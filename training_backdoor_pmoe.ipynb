{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1750841614805,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "qMkNHM0g5Qke",
    "outputId": "8db0a19a-4c27-4e71-cec7-eb961e9eeb73"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install --upgrade pip\n",
    "# !pip install empatches\n",
    "# !pip install tensorflow\n",
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750841614839,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "kmAdfc8GSnzY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 14:13:43.178944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-29 14:13:43.203665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751199223.224240 1132618 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751199223.230580 1132618 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751199223.247147 1132618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751199223.247165 1132618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751199223.247167 1132618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751199223.247168 1132618 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-29 14:13:43.254770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from empatches import EMPatches\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from random import random\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import traceback\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750841615821,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "yQfrshqK120J"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "dataset = 'CIFAR-10' # 'CIFAR-10' , 'GTSRB'\n",
    "trigger = 'blend' # 'square' , 'blend' , 'warped'\n",
    "# poisoning_rate = 0.0001  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "poisoning_rate = 0.0005  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "# poisoning_rate = 0.001  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "# poisoning_rate = 0.005  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "# poisoning_rate = 0.02  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "# poisoning_rate = 0.06  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "# poisoning_rate = 0.1  # 2% poisoning rate, adjust this to other poisoning rates\n",
    "\n",
    "_warping = 0.025\n",
    "weight = 0.78\n",
    "_size = 1\n",
    "n_experts = 4\n",
    "patch_level = True # False for trigger on entire image\n",
    "\n",
    "train = False\n",
    "save_model = False\n",
    "load_model = True\n",
    "target_label = 0    # Target label for backdoor attack\n",
    "source_label = None    # Source label for backdoor attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-ycU9O-5Qkg"
   },
   "source": [
    "# Gating Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750841615830,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "cHgmRT3H5Qkg"
   },
   "outputs": [],
   "source": [
    "class gate(tf.keras.layers.Layer):\n",
    "    def __init__(self, k, gating_kernel_size, strides=(1,1), padding = 'valid',\n",
    "                 data_format = 'channels_last', gating_activation = None,\n",
    "                 gating_kernel_initializer = tf.keras.initializers.RandomNormal, **kwargs):\n",
    "\n",
    "        super(gate, self).__init__(**kwargs)\n",
    "        self.k = k\n",
    "        self.gating_kernel_size = gating_kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.data_format = data_format\n",
    "        self.gating_activation = tf.keras.activations.get(gating_activation)\n",
    "        self.gating_kernel_initializer = gating_kernel_initializer\n",
    "        self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n",
    "\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        gating_kernel_shape = self.gating_kernel_size + (input_dim, 1)\n",
    "        self.gating_kernel = self.add_weight(shape=gating_kernel_shape,\n",
    "                                      initializer=self.gating_kernel_initializer,\n",
    "                                      name='gating_kernel')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        gating_outputs = tf.keras.backend.conv2d(inputs, self.gating_kernel, strides=self.strides,\n",
    "                                  padding=self.padding,data_format=self.data_format)\n",
    "\n",
    "        gating_outputs = tf.transpose(gating_outputs, perm=(0,3,1,2))\n",
    "        x = tf.shape(gating_outputs)[2]\n",
    "        y = tf.shape(gating_outputs)[3]\n",
    "        gating_outputs = tf.reshape(gating_outputs,(tf.shape(gating_outputs)[0],tf.shape(gating_outputs)[1],\n",
    "                                                    x*y))\n",
    "\n",
    "        gating_outputs = self.gating_activation(gating_outputs)\n",
    "        # print(\"gating output: \", gating_outputs.shape)\n",
    "        [values, indices] = tf.math.top_k(gating_outputs,k=self.k, sorted=False)\n",
    "        # print(\"value output: \", values.shape)\n",
    "        # print(\"indice before output: \", indices.shape)\n",
    "        indices = tf.reshape(indices,(tf.shape(indices)[0]*tf.shape(indices)[1],tf.shape(indices)[2]))\n",
    "        # print(\"indice after output: \", indices.shape)\n",
    "        values = tf.reshape(values, (tf.shape(values)[0]*tf.shape(values)[1], tf.shape(values)[2]))\n",
    "        batch_t, k_t = tf.unstack(tf.shape(indices), num=2)\n",
    "\n",
    "        n=tf.shape(gating_outputs)[2]\n",
    "\n",
    "        indices_flat = tf.reshape(indices, [-1]) + tf.math.floordiv(tf.range(batch_t * k_t), k_t) * n\n",
    "        ret_flat = tf.math.unsorted_segment_sum(tf.reshape(values, [-1]), indices_flat, batch_t * n)\n",
    "        ret_rsh=tf.reshape(ret_flat, [batch_t, n])\n",
    "        ret_rsh_3=tf.reshape(ret_rsh,(tf.shape(gating_outputs)[0],tf.shape(gating_outputs)[1],tf.shape(gating_outputs)[2]))\n",
    "\n",
    "        new_gating_outputs = tf.reshape(ret_rsh_3,(tf.shape(ret_rsh_3)[0],tf.shape(ret_rsh_3)[1],x,y))\n",
    "        new_gating_outputs = tf.transpose(new_gating_outputs, perm=(0,2,3,1))\n",
    "        new_gating_outputs = tf.repeat(new_gating_outputs,tf.shape(self.gating_kernel)[0]*tf.shape(self.gating_kernel)[1]*tf.shape(self.gating_kernel)[2],axis=3)\n",
    "        new_gating_outputs=tf.reshape(new_gating_outputs,(tf.shape(new_gating_outputs)[0],tf.shape(new_gating_outputs)[1],tf.shape(new_gating_outputs)[2],tf.shape(self.gating_kernel)[0],tf.shape(self.gating_kernel)[1],tf.shape(self.gating_kernel)[2]))\n",
    "        new_gating_outputs=tf.transpose(new_gating_outputs,perm=(0,1,3,2,4,5))\n",
    "        new_gating_outputs=tf.reshape(new_gating_outputs,(tf.shape(new_gating_outputs)[0],tf.shape(new_gating_outputs)[1]*tf.shape(new_gating_outputs)[2],tf.shape(new_gating_outputs)[3]*tf.shape(new_gating_outputs)[4],tf.shape(new_gating_outputs)[5]))\n",
    "        outputs = inputs*new_gating_outputs\n",
    "        return outputs, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SERp0GMl5Qkh"
   },
   "source": [
    "# Wideresnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750841615839,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "qMoWs8YN5Qkh"
   },
   "outputs": [],
   "source": [
    "initializer_gate=keras.initializers.RandomNormal(mean=0.0,stddev=0.0001)\n",
    "\n",
    "def WideResnetBlock(x, channels, strides, channel_mismatch=False):\n",
    "\n",
    "    identity = x\n",
    "\n",
    "    out = layers.BatchNormalization()(x)\n",
    "    out = layers.ReLU()(out)\n",
    "    out = layers.Conv2D(filters=channels, kernel_size=3, strides=strides, padding='same')(out)\n",
    "\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.ReLU()(out)\n",
    "    out = layers.Conv2D(filters=channels, kernel_size=3, strides=1, padding='same')(out)\n",
    "\n",
    "    if channel_mismatch is not False:\n",
    "        identity = layers.Conv2D(filters=channels, kernel_size=1, strides=strides, padding='valid')(identity)\n",
    "\n",
    "    out = layers.Add()([identity, out])\n",
    "\n",
    "    return out\n",
    "\n",
    "def WideResnetGroup(x, num_blocks, channels, strides):\n",
    "\n",
    "    x = WideResnetBlock(x=x, channels=channels, strides=strides, channel_mismatch=True)\n",
    "\n",
    "    for _ in range(num_blocks - 1):\n",
    "        x = WideResnetBlock(x=x, channels=channels, strides=(1, 1))\n",
    "\n",
    "    return x\n",
    "\n",
    "def WideResnet(x, num_blocks, k, num_classes=10):\n",
    "    widths = [int(v * k) for v in (16, 32, 64)]\n",
    "\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = WideResnetGroup(x, num_blocks, widths[0], strides=(1, 1))\n",
    "    x = WideResnetGroup(x, num_blocks, widths[1], strides=(2, 2))\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters=640, kernel_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    x_1, indices_1 = gate(16,(1,1),(1,1),gating_activation=tf.nn.softmax,gating_kernel_initializer=initializer_gate)(x)\n",
    "    x_2, indices_2 = gate(16,(1,1),(1,1),gating_activation=tf.nn.softmax,gating_kernel_initializer=initializer_gate)(x)\n",
    "    x_3, indices_3 = gate(16,(1,1),(1,1),gating_activation=tf.nn.softmax,gating_kernel_initializer=initializer_gate)(x)\n",
    "    x_4, indices_4 = gate(16,(1,1),(1,1),gating_activation=tf.nn.softmax,gating_kernel_initializer=initializer_gate)(x)\n",
    "\n",
    "    x_1 = layers.BatchNormalization()(x_1)\n",
    "    x_2 = layers.BatchNormalization()(x_2)\n",
    "    x_3 = layers.BatchNormalization()(x_3)\n",
    "    x_4 = layers.BatchNormalization()(x_4)\n",
    "\n",
    "    x_1 = layers.ReLU()(x_1)\n",
    "    x_2 = layers.ReLU()(x_2)\n",
    "    x_3 = layers.ReLU()(x_3)\n",
    "    x_4 = layers.ReLU()(x_4)\n",
    "\n",
    "    x_1 = layers.Conv2D(filters=160, kernel_size=1, strides=1, padding='same')(x_1)\n",
    "    x_2 = layers.Conv2D(filters=160, kernel_size=1, strides=1, padding='same')(x_2)\n",
    "    x_3 = layers.Conv2D(filters=160, kernel_size=1, strides=1, padding='same')(x_3)\n",
    "    x_4 = layers.Conv2D(filters=160, kernel_size=1, strides=1, padding='same')(x_4)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([x_1, x_2, x_3, x_4])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.AveragePooling2D((8,8))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units=num_classes, activation='softmax')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-d9cWBl5Qki"
   },
   "source": [
    "# Trigger generation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1750841615876,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "3ySd1qQa5Qki"
   },
   "outputs": [],
   "source": [
    "class GenerateSQRTrigger:\n",
    "    \"\"\"\n",
    "    A class that creates a random square pattern that is used as a trigger for an\n",
    "    image dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, pos_label, dataset='mnist'):\n",
    "\n",
    "        datasets_dimensions = {\"mnist\": (28, 28, 1),\n",
    "                               \"cifar10\": (32, 32, 3),\n",
    "                               \"fmnist\": (28, 28, 1)}\n",
    "\n",
    "        dims = datasets_dimensions[dataset]\n",
    "\n",
    "        if size[0] != size[1]:\n",
    "            raise Exception(\"The size of the trigger must be square.\")\n",
    "\n",
    "        if pos_label.lower() not in [\"upper-left\", \"upper-mid\", \"upper-right\", \"mid-left\", \"mid-mid\", \"mid-right\",\n",
    "                                     \"lower-left\",\n",
    "                                     \"lower-mid\", \"lower-right\"]:\n",
    "            raise Exception(\n",
    "                \"The position of the trigger must be one of the following: upper-left, upper-mid, upper-right, mid-left, mid-mid, mid-right, lower-left, lower-mid, lower-right\")\n",
    "\n",
    "        if size[0] > dims[0] or size[1] > dims[1]:\n",
    "            raise Exception(\"The size of the trigger is too large for the dataset items.\")\n",
    "\n",
    "        self.dims = dims\n",
    "        self.size = size\n",
    "        self.pos_label = pos_label\n",
    "        self.pos_coords = self._gen_pos_square()\n",
    "\n",
    "        trigger = np.zeros(self.dims, dtype=np.float32)\n",
    "        self.crafted_trigger = self.create_trigger_square(trigger)\n",
    "\n",
    "    def _gen_pos_square(self):\n",
    "        if self.pos_label == \"upper-left\":\n",
    "            return (0, 0)\n",
    "        elif self.pos_label == \"upper-mid\":\n",
    "            return (0, self.dims[1] // 2 - self.size[1] // 2)\n",
    "        elif self.pos_label == \"upper-right\":\n",
    "            return (0, self.dims[1] - self.size[1])\n",
    "\n",
    "        elif self.pos_label == \"mid-left\":\n",
    "            return (self.dims[0] // 2 - self.size[0] // 2, 0)\n",
    "        elif self.pos_label == \"mid-mid\":\n",
    "            return (self.dims[0] // 2 - self.size[0] // 2,\n",
    "                    self.dims[1] // 2 - self.size[1] // 2)\n",
    "        elif self.pos_label == \"mid-right\":\n",
    "            return (self.dims[0] // 2 - self.size[0] // 2, self.dims[1] - self.size[1])\n",
    "\n",
    "        elif self.pos_label == \"lower-left\":\n",
    "            return (self.dims[0] - self.size[0], 0)\n",
    "        elif self.pos_label == \"lower-mid\":\n",
    "            return (self.dims[0] - self.size[0], self.dims[1] // 2 - self.size[1] // 2)\n",
    "        elif self.pos_label == \"lower-right\":\n",
    "            return (self.dims[0] - self.size[0], self.dims[1] - self.size[1])\n",
    "\n",
    "    def create_trigger_square(self, trigger):\n",
    "        \"\"\"Create a square trigger.\"\"\"\n",
    "        base_x, base_y = self.pos_coords\n",
    "        for x in range(self.size[0]):\n",
    "            for y in range(self.size[1]):\n",
    "                trigger[base_x + x][base_y + y] = \\\n",
    "                    np.ones((self.dims[2]))\n",
    "\n",
    "        return trigger\n",
    "\n",
    "    def apply_trigger(self, img):\n",
    "        \"\"\"applies the trigger on the image.\"\"\"\n",
    "\n",
    "        base_x, base_y = self.pos_coords\n",
    "        for x in range(self.size[0]):\n",
    "            for y in range(self.size[1]):\n",
    "                img[base_x + x][base_y + y] = self.crafted_trigger[base_x + x][base_y + y]\n",
    "        return img\n",
    "\n",
    "class GenerateBlendedTrigger:\n",
    "    \"\"\"\n",
    "    A class that uses images of the same dimensions as the dataset as triggers\n",
    "    that will be blended with the clean images.\n",
    "\n",
    "    We will use a random pattern or a hello-kitty image as the original paper\n",
    "    (https://arxiv.org/pdf/1712.05526.pdf).\n",
    "    \"\"\"\n",
    "    hello_kitty_path = \"/home/jtelintelo/pmoe_backdoor/hello_kitty.jpg\"\n",
    "\n",
    "    def __init__(self, dataset, trigger):\n",
    "\n",
    "        datasets_dimensions = {\"mnist\": (28, 28, 1),\n",
    "                               \"cifar10\": (32, 32, 3),\n",
    "                               \"fmnist\": (28, 28, 1)}\n",
    "\n",
    "        dims = datasets_dimensions[dataset]\n",
    "\n",
    "        if trigger not in [\"random\", \"hello-kitty\"]:\n",
    "            raise Exception(f\"Pick 'random' or 'hello-kitty' trigger\")\n",
    "\n",
    "        if dataset not in datasets_dimensions:\n",
    "            raise Exception(f\"Dataset is not supported\")\n",
    "\n",
    "        self.dims = dims\n",
    "        self.dataset = dataset\n",
    "\n",
    "        # Generate the correct trigger\n",
    "        self.crafted_trigger = self.trigger_blended(trigger)\n",
    "\n",
    "    def trigger_blended(self, trigger):\n",
    "        \"\"\"Prepare the trigger for blended attack.\"\"\"\n",
    "        if trigger == \"hello-kitty\":\n",
    "            # Load kitty\n",
    "            img = Image.open(self.hello_kitty_path)\n",
    "\n",
    "            # Resize to dimensions\n",
    "            tmp = img.resize(self.dims[:-1])\n",
    "\n",
    "            if self.dims[2] == 1:\n",
    "                tmp = ImageOps.grayscale(tmp)\n",
    "\n",
    "            tmp = np.asarray(tmp)\n",
    "            # This is needed in case the image is grayscale (width x height) to\n",
    "            # add the channel dimension\n",
    "            tmp = tmp.reshape((self.dims))\n",
    "            # print(type(tmp))\n",
    "            # print(tmp.shape)\n",
    "            if patch_level:\n",
    "              pil_image = Image.fromarray(tmp)\n",
    "              resized_pil = pil_image.resize((8,8))\n",
    "              tmp = np.array(resized_pil)\n",
    "            # print(type(tmp))\n",
    "            # print(tmp.shape)\n",
    "            # plt.figure(figsize=(3, 3))\n",
    "            # plt.imshow((tmp), cmap='gray')\n",
    "            # plt.axis('off')\n",
    "            # plt.title(\"blended patch|\")\n",
    "            # plt.show()\n",
    "            # dd\n",
    "            # print(tmp.shape)\n",
    "            trigger_array = tmp / 255\n",
    "        else:\n",
    "            # Create a np.array with the correct dimensions\n",
    "            # fill the pixels with random values\n",
    "            trigger_array = (np.random.random((self.dims)))\n",
    "\n",
    "        return trigger_array\n",
    "\n",
    "    def apply_trigger(self, img):\n",
    "        \"\"\"applies the trigger on the image.\"\"\"\n",
    "        crafted_trigger_normalized = self.crafted_trigger\n",
    "        if crafted_trigger_normalized.max() > 1:\n",
    "            crafted_trigger_normalized = crafted_trigger_normalized / 255.0\n",
    "        # Ensure the input image is normalized to [0, 1]\n",
    "        if img.max() > 1:\n",
    "            img = img / 255.0\n",
    "\n",
    "        # Blend the images\n",
    "        img = ((img*weight) + (crafted_trigger_normalized*(1-weight)))\n",
    "        # plt.figure(figsize=(4, 4))\n",
    "        # plt.imshow(img, cmap='gray' if self.dims[-1] == 1 else None)\n",
    "        # plt.axis('off')\n",
    "        # plt.title(\"Crafted Trigger\")\n",
    "        # plt.show()\n",
    "        # print(f\"Blended image min: {img.min()}, max: {img.max()}\")\n",
    "        return img.astype(np.float32)\n",
    "\n",
    "class GenerateWarpedTrigger:\n",
    "    \"\"\"\n",
    "    A class that generates a warped trigger using a distortion grid for backdoor attacks.\n",
    "    Compatible with TensorFlow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, s=_warping, grid_rescale=1.0, k = 2, input_height = 32):\n",
    "        \"\"\"\n",
    "        Initialize the warped trigger generator.\n",
    "        :param dataset: Dataset name (e.g., 'mnist', 'cifar10', etc.) for defining image dimensions.\n",
    "        :param s: Strength of the warping effect.\n",
    "        :param grid_rescale: Rescaling factor for the distortion grid.\n",
    "        \"\"\"\n",
    "        datasets_dimensions = {\"mnist\": (28, 28, 1),\n",
    "                               \"cifar10\": (32, 32, 3),\n",
    "                               \"fmnist\": (28, 28, 1)}\n",
    "\n",
    "        if dataset not in datasets_dimensions:\n",
    "            raise Exception(f\"Dataset is not supported\")\n",
    "\n",
    "        self.dims = datasets_dimensions[dataset]\n",
    "        self.s = s\n",
    "        self.k = k\n",
    "        self.input_height = input_height\n",
    "        self.grid_rescale = grid_rescale\n",
    "\n",
    "        # Initialize the identity grid and noise grid for warping\n",
    "        self.identity_grid, self.noise_grid = self.generate_main_grid()\n",
    "\n",
    "    def generate_main_grid(self):\n",
    "        \"\"\"\n",
    "        Generate the identity and noise grids for the warped trigger.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create coarse random noise grid\n",
    "        grid_noise = tf.random.uniform(\n",
    "            shape=(1, self.k, self.k, 2), minval=-1.0, maxval=1.0\n",
    "        )\n",
    "        grid_noise = grid_noise / tf.reduce_mean(tf.abs(grid_noise))\n",
    "\n",
    "        # Upsample the coarse noise to match the input height and width\n",
    "        noise_grid = tf.image.resize(grid_noise, size=(self.input_height, self.input_height), method=\"bicubic\")\n",
    "        noise_grid = tf.clip_by_value(noise_grid, -1.0, 1.0)  # Clamp values for stability\n",
    "\n",
    "        # Create the identity grid\n",
    "        array1d = tf.linspace(-1.0, 1.0, self.input_height)\n",
    "        x, y = tf.meshgrid(array1d, array1d)\n",
    "        identity_grid = tf.stack([y, x], axis=-1)\n",
    "        identity_grid = identity_grid[tf.newaxis, ...]  # Add batch dimension\n",
    "\n",
    "        return identity_grid, noise_grid\n",
    "\n",
    "    def _grid_sample(self, image, grid):\n",
    "        \"\"\"\n",
    "        TensorFlow implementation of grid sampling for image warping.\n",
    "        :param image: The input image tensor with shape (batch_size, height, width, channels).\n",
    "        :param grid: The grid tensor with shape (batch_size, height, width, 2).\n",
    "        :return: Warped image tensor.\n",
    "        \"\"\"\n",
    "        batch_size, height, width, channels = image.shape\n",
    "\n",
    "        # Split grid into x and y components\n",
    "        grid_y, grid_x = tf.split(grid, 2, axis=-1)\n",
    "\n",
    "        # Rescale normalized grid coordinates to image pixel indices\n",
    "        grid_x = tf.cast((grid_x + 1.0) * 0.5 * tf.cast(width - 1, tf.float32), tf.int32)\n",
    "        grid_y = tf.cast((grid_y + 1.0) * 0.5 * tf.cast(height - 1, tf.float32), tf.int32)\n",
    "\n",
    "        # Remove the last dimension of grid_x and grid_y to match batch_indices shape\n",
    "        grid_x = tf.squeeze(grid_x, axis=-1)  # Shape: (batch_size, height, width)\n",
    "        grid_y = tf.squeeze(grid_y, axis=-1)  # Shape: (batch_size, height, width)\n",
    "\n",
    "        # Create batch indices for gather_nd\n",
    "        batch_indices = tf.range(batch_size)[:, tf.newaxis, tf.newaxis]  # Shape: (batch_size, 1, 1)\n",
    "        batch_indices = tf.tile(batch_indices, [1, height, width])  # Shape: (batch_size, height, width)\n",
    "\n",
    "        # Clip grid indices to stay within image bounds\n",
    "        grid_x = tf.clip_by_value(grid_x, 0, width - 1)\n",
    "        grid_y = tf.clip_by_value(grid_y, 0, height - 1)\n",
    "\n",
    "        # Stack indices for gather_nd\n",
    "        indices = tf.stack([batch_indices, grid_y, grid_x], axis=-1)\n",
    "\n",
    "        sampled_image = tf.gather_nd(image, indices)\n",
    "\n",
    "        return sampled_image\n",
    "\n",
    "    def poison(self, image):\n",
    "        \"\"\"\n",
    "        Apply a warping trigger to the image.\n",
    "        :param image: A NumPy array representing the input image.\n",
    "        :return: A NumPy array of the warped image.\n",
    "        \"\"\"\n",
    "        # Ensure the input image is normalized\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "\n",
    "        # Expand dimensions to (batch_size, height, width, channels)\n",
    "        image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        if len(image_tensor.shape) == 3:  # Add batch dimension if missing\n",
    "            image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "        # Generate the warped grid\n",
    "        grid_temps = (self.identity_grid + self.s * self.noise_grid / self.input_height) * self.grid_rescale\n",
    "        grid_temps = tf.clip_by_value(grid_temps, -1.0, 1.0)\n",
    "\n",
    "        # Warp the image using TensorFlow's grid_sample equivalent\n",
    "        poisoned_image = self._grid_sample(image_tensor, grid_temps)\n",
    "\n",
    "        # Squeeze batch dimension and convert back to NumPy\n",
    "        poisoned_image = tf.squeeze(poisoned_image, axis=0).numpy()\n",
    "\n",
    "        return poisoned_image\n",
    "\n",
    "\n",
    "    def apply_trigger(self, img):\n",
    "        \"\"\"\n",
    "        Alias for the poison function for consistency with other trigger generators.\n",
    "        :param img: Input image as a NumPy array.\n",
    "        :return: Warped image as a NumPy array.\n",
    "        \"\"\"\n",
    "        return self.poison(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFNe3RD19qe3"
   },
   "source": [
    "# Creating backdoor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750841615896,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "BBMzxM7Y5Qki"
   },
   "outputs": [],
   "source": [
    "class BackdoorDataset:\n",
    "  \"\"\"\n",
    "  TensorFlow-compatible dataset for backdoor attacks, enabling poisoning of specific samples.\n",
    "  \"\"\"\n",
    "  def __init__(self, clean_data, clean_labels, trigger_obj, epsilon=0.08,\n",
    "                target_label=None, source_label=None, train=True, cifar=True):\n",
    "    \"\"\"\n",
    "    Initialize the backdoor dataset.\n",
    "    :param clean_data: Original dataset images (NumPy array).\n",
    "    :param clean_labels: Original dataset labels (one-hot encoded NumPy array).\n",
    "    :param trigger_obj: Instance of the GenerateSQRTrigger class.\n",
    "    :param epsilon: Fraction of samples to poison (default: 0.08 or 8%).\n",
    "    :param target_label: The target label for poisoned samples.\n",
    "    :param source_label: The source label for poisoned samples.\n",
    "    :param train: Whether this dataset is for training or testing.\n",
    "    \"\"\"\n",
    "    self.clean_data = clean_data\n",
    "    self.clean_labels = clean_labels\n",
    "    self.trigger_obj = trigger_obj\n",
    "    self.epsilon = epsilon\n",
    "    self.target_label = target_label\n",
    "    self.source_label = source_label\n",
    "    self.train = train\n",
    "    self.cifar = cifar\n",
    "\n",
    "    if train:\n",
    "      self.poisoned_data, self.poisoned_labels = self.get_train_set()\n",
    "    else:\n",
    "      self.poisoned_data, self.poisoned_labels = self.get_test_set()\n",
    "\n",
    "  def poison(self, img):\n",
    "    \"\"\"Poison an image by applying the trigger.\"\"\"\n",
    "    if patch_level:\n",
    "      emp = EMPatches()\n",
    "      img_patches, indices = emp.extract_patches(img, patchsize=8, overlap=0)\n",
    "      for index, patch in enumerate(img_patches):\n",
    "        img_patches[index] = self.trigger_obj.apply_trigger(patch)\n",
    "      poisoned_img = emp.merge_patches(img_patches, indices)\n",
    "      # plt.figure(figsize=(3, 3))\n",
    "      # plt.imshow(poisoned_img)\n",
    "      # plt.axis('off')\n",
    "      # plt.title(\"Crafted Trigger\")\n",
    "      # plt.show()\n",
    "    else:\n",
    "      poisoned_img = self.trigger_obj.apply_trigger(img)\n",
    "    return poisoned_img\n",
    "\n",
    "  def get_train_set(self):\n",
    "    \"\"\"Generate the poisoned training set.\"\"\"\n",
    "    poisoned_data = np.copy(self.clean_data)\n",
    "    if (isinstance(self.trigger_obj, GenerateBlendedTrigger) and self.trigger_obj.crafted_trigger is not None) or \\\n",
    "    isinstance(self.trigger_obj, GenerateWarpedTrigger):\n",
    "      poisoned_data = poisoned_data / 255  # Apply normalization\n",
    "\n",
    "    poisoned_labels = np.copy(self.clean_labels)\n",
    "\n",
    "    num_samples = self.clean_data.shape[0]\n",
    "    num_poisoned = int(self.epsilon * num_samples)\n",
    "    poisoned_indices = np.random.choice(num_samples, size=num_poisoned, replace=False)\n",
    "\n",
    "    for idx in poisoned_indices:\n",
    "      label_idx = np.argmax(self.clean_labels[idx])  # Convert one-hot label to scalar\n",
    "\n",
    "      if self.source_label is not None:\n",
    "        if label_idx == self.source_label:\n",
    "          # Poison data and change the label to target label\n",
    "          poisoned_data[idx] = self.poison(self.clean_data[idx])\n",
    "          if self.cifar is True:\n",
    "            poisoned_labels[idx] = tf.one_hot(self.target_label, depth=10).numpy()\n",
    "          else:\n",
    "            poisoned_labels[idx] = tf.one_hot(self.target_label, depth=43).numpy()\n",
    "        else:\n",
    "          # Poison data but keep the original label\n",
    "          poisoned_data[idx] = self.poison(self.clean_data[idx])\n",
    "          # Label remains unchanged\n",
    "      else:\n",
    "        # Poison data and always change the label to target label\n",
    "        poisoned_data[idx] = self.poison(self.clean_data[idx])\n",
    "        if self.cifar is True:\n",
    "          poisoned_labels[idx] = tf.one_hot(self.target_label, depth=10).numpy()\n",
    "        else:\n",
    "          poisoned_labels[idx] = tf.one_hot(self.target_label, depth=43).numpy()\n",
    "\n",
    "    return poisoned_data, poisoned_labels\n",
    "\n",
    "  def get_test_set(self):\n",
    "    \"\"\"Generate the poisoned test set.\"\"\"\n",
    "    temp = deepcopy(self.clean_data)\n",
    "    poisoned_data = []\n",
    "    poisoned_labels = []\n",
    "\n",
    "    for idx in range(self.clean_data.shape[0]):\n",
    "      label_idx = np.argmax(self.clean_labels[idx])  # Convert one-hot label to scalar\n",
    "      if label_idx != self.target_label:\n",
    "        poisoned_data.append(self.poison(temp[idx]))\n",
    "        poisoned_labels.append(self.clean_labels[idx])\n",
    "    return np.array(poisoned_data), np.array(poisoned_labels)\n",
    "\n",
    "  def get_data(self):\n",
    "    \"\"\"Return the poisoned dataset.\"\"\"\n",
    "    return self.poisoned_data, self.poisoned_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgbO-SZ59qe4"
   },
   "source": [
    "# Attack evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750841615903,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "ci5hdeSn5Qkj"
   },
   "outputs": [],
   "source": [
    "def find_source_indices(labels, source_label):\n",
    "    \"\"\"\n",
    "    Find indices of samples with the source label.\n",
    "    \"\"\"\n",
    "    indices = np.where(labels == source_label)[0]\n",
    "    return indices\n",
    "\n",
    "def find_non_source_indices(labels, source_label, target_label):\n",
    "    \"\"\"\n",
    "    Find indices of samples which do not have the source or target label.\n",
    "    \"\"\"\n",
    "    indices = np.where((labels != source_label) & (labels != target_label))[0]\n",
    "    return indices\n",
    "\n",
    "def count_non_source_misclassifications(original_labels, predicted_labels, source_label, target_label):\n",
    "    \"\"\"\n",
    "    Count misclassifications for non-source and non-target label samples.\n",
    "    \"\"\"\n",
    "    sub_non_source_total = 0\n",
    "    sub_misclassifications = 0\n",
    "\n",
    "    indices = find_non_source_indices(original_labels, source_label, target_label)\n",
    "    sub_non_source_total += len(indices)\n",
    "\n",
    "    for index in indices:\n",
    "        if predicted_labels[index] == target_label:\n",
    "            sub_misclassifications += 1\n",
    "    return sub_misclassifications, sub_non_source_total\n",
    "\n",
    "def count_source_specific_classifications(original_labels, predicted_labels, source_label, target_label):\n",
    "    \"\"\"\n",
    "    Count correct classifications for source label samples to target label.\n",
    "    \"\"\"\n",
    "    sub_total = 0\n",
    "    sub_correct = 0\n",
    "\n",
    "    indices = find_source_indices(original_labels, source_label)\n",
    "    sub_total += len(indices)\n",
    "\n",
    "    for index in indices:\n",
    "        if predicted_labels[index] == target_label:\n",
    "            sub_correct += 1\n",
    "    return sub_correct, sub_total\n",
    "\n",
    "def calculate_ASR(model, test_data, test_labels, target_label, source_label=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate the Attack Success Rate (ASR) of the backdoored model.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    non_source_total = 0\n",
    "    misclassifications = 0\n",
    "\n",
    "    # Get model predictions\n",
    "    predictions = model.predict(test_data, batch_size=128)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    original_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    if source_label is not None:\n",
    "        # Source-specific attack\n",
    "        sub_correct, sub_total = count_source_specific_classifications(original_labels, predicted_labels, source_label, target_label)\n",
    "        correct += sub_correct\n",
    "        total += sub_total\n",
    "\n",
    "        if verbose:\n",
    "            sub_misclassifications, sub_non_source_total = count_non_source_misclassifications(original_labels, predicted_labels, source_label, target_label)\n",
    "            misclassifications += sub_misclassifications\n",
    "            non_source_total += sub_non_source_total\n",
    "    else:\n",
    "        # Source-agnostic attack\n",
    "        for i in range(len(original_labels)):\n",
    "            if original_labels[i] != target_label:\n",
    "                total += 1\n",
    "                # print(\"original: \", original_labels[i], \"predict: \", predicted_labels[i])\n",
    "                if predicted_labels[i] == target_label:\n",
    "                    correct += 1\n",
    "\n",
    "\n",
    "    attack_acc = (correct * 100.0) / total\n",
    "    print(f\"Attack accuracy: {round(attack_acc, 2)}%\")\n",
    "\n",
    "    if source_label and verbose:\n",
    "        print(f\"Misclassifications: {misclassifications}\")\n",
    "        print(f\"Non-source total: {non_source_total}\")\n",
    "        misclassification_rate = (misclassifications * 100.0) / non_source_total\n",
    "        print(f\"False Positive Rate: {round(misclassification_rate, 2)}%\")\n",
    "\n",
    "    return attack_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FoMExvQ5Qkj"
   },
   "source": [
    "# Backdoor training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1750841616407,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "A_o7JimEGKvC",
    "outputId": "c7d4c3c3-d162-4d4a-af2b-f05d1f748a5b"
   },
   "outputs": [],
   "source": [
    "# testing_data = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/cifar_10_test_data_sorted.npy')\n",
    "# testing_label = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/cifar_10_test_label_sorted.npy')\n",
    "# image_patch = testing_data[5536:5537]\n",
    "# plt.figure(figsize=(3, 3))\n",
    "# plt.imshow((image_patch[0]), cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.title(\"Crafted Trigger\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1750841616685,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "E8cJ6g_EEPPh",
    "outputId": "ce1cb74c-8767-4a05-f6e3-64bd233dfc89"
   },
   "outputs": [],
   "source": [
    "# trigger_generator = GenerateWarpedTrigger(\"cifar10\", input_height = 8 if patch_level else 32)\n",
    "# patch_level = True\n",
    "# backdoor_test_dataset = BackdoorDataset(\n",
    "#   clean_data=testing_data[5536:5537],\n",
    "#   clean_labels=tf.one_hot(testing_label[5536:5537], depth=10).numpy(),\n",
    "#   trigger_obj=trigger_generator,  # Adjust this as needed for the trigger type\n",
    "#   epsilon=poisoning_rate,  # Apply the same poisoning rate as training\n",
    "#   target_label=target_label,\n",
    "#   source_label=source_label,\n",
    "#   train=False  # Specify that this is for testing\n",
    "# )\n",
    "# poisoned_testing_data, poisoned_testing_label = backdoor_test_dataset.get_data()\n",
    "# poisoned_testing_data = tf.cast(poisoned_testing_data, dtype=tf.dtypes.float32)\n",
    "\n",
    "# image_patch = poisoned_testing_data\n",
    "# plt.figure(figsize=(3, 3))\n",
    "# plt.imshow((image_patch[0]), cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.title(\"Crafted Trigger\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1750841616869,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "p2rSZxcdE1Im",
    "outputId": "5f79e563-ec74-4925-9a8b-e1f75304a1f8"
   },
   "outputs": [],
   "source": [
    "# trigger_generator = GenerateBlendedTrigger(\"cifar10\", \"hello-kitty\")\n",
    "# patch_level = True\n",
    "# backdoor_test_dataset = BackdoorDataset(\n",
    "#   clean_data=testing_data[5536:5537],\n",
    "#   clean_labels=tf.one_hot(testing_label[5536:5537], depth=10).numpy(),\n",
    "#   trigger_obj=trigger_generator,  # Adjust this as needed for the trigger type\n",
    "#   epsilon=poisoning_rate,  # Apply the same poisoning rate as training\n",
    "#   target_label=target_label,\n",
    "#   source_label=source_label,\n",
    "#   train=False  # Specify that this is for testing\n",
    "# )\n",
    "# poisoned_testing_data, poisoned_testing_label = backdoor_test_dataset.get_data()\n",
    "# poisoned_testing_data = tf.cast(poisoned_testing_data, dtype=tf.dtypes.float32)\n",
    "\n",
    "# image_patch = poisoned_testing_data\n",
    "# plt.figure(figsize=(3, 3))\n",
    "# plt.imshow((image_patch[0]), cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.title(\"Crafted Trigger\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "error",
     "timestamp": 1750841616967,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "dv3_kyYz5Qkj",
    "outputId": "71e2786f-690f-45b0-ddd3-3a36ebce6a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 as dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751199230.383365 1132618 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38484 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:31:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751199234.726659 1133417 service.cc:152] XLA service 0x145a3c005a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751199234.726693 1133417 service.cc:160]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2025-06-29 14:13:54.802200: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751199234.971628 1133417 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-06-29 14:13:55.875657: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_578', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-06-29 14:13:56.268066: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_578', 4700 bytes spill stores, 4772 bytes spill loads\n",
      "\n",
      "2025-06-29 14:13:56.430091: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_578', 6016 bytes spill stores, 5864 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/71\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751199238.441441 1133417 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 14:14:00.755941: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2482', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-06-29 14:14:00.953825: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2482', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-06-29 14:14:01.317337: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2482', 1960 bytes spill stores, 2060 bytes spill loads\n",
      "\n",
      "2025-06-29 14:14:01.515221: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2482', 6108 bytes spill stores, 6064 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step\n",
      "Attack accuracy: 18.36%\n",
      "Attack Success Rate (ASR) for s=50000: 18.355555555555554%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if trigger == 'square':\n",
    "  trigger_generator = GenerateSQRTrigger((_size, _size), 'upper-left')\n",
    "if trigger == 'blend':\n",
    "  trigger_generator = GenerateBlendedTrigger(\"cifar10\", \"hello-kitty\")\n",
    "if trigger == 'warped':\n",
    "  trigger_generator = GenerateWarpedTrigger(\"cifar10\", input_height = 8 if patch_level else 32)\n",
    "\n",
    "if dataset == 'CIFAR-10':\n",
    "  print(\"CIFAR-10 as dataset\")\n",
    "  training_data_all = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/cifar_10_train_data_sorted.npy')\n",
    "  training_label_all = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/cifar_10_train_label_sorted.npy')\n",
    "  testing_data = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/cifar_10_test_data_sorted.npy')\n",
    "  testing_label = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/cifar_10_test_label_sorted.npy')\n",
    "\n",
    "if dataset == 'GTSRB':\n",
    "  print(\"GTSRB as dataset\")\n",
    "  training_data = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/gtsrb_train_data_sorted.npy')\n",
    "  training_label = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/gtsrb_train_label_sorted.npy')\n",
    "  testing_data = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/gtsrb_test_data_sorted.npy')\n",
    "  testing_label = np.load('/home/jtelintelo/pmoe_backdoor/backdoor_datasets/gtsrb_test_label_sorted.npy')\n",
    "\n",
    "for s in [50000]:\n",
    "  # Loading the Data\n",
    "  if dataset == 'CIFAR-10':\n",
    "    # Sampling training data\n",
    "    training_data = np.concatenate((training_data_all[0:0+(s//10)], training_data_all[5000:5000+(s//10)],\n",
    "                                    training_data_all[10000:10000+(s//10)], training_data_all[15000:15000+(s//10)],\n",
    "                                    training_data_all[20000:20000+(s//10)], training_data_all[25000:25000+(s//10)],\n",
    "                                    training_data_all[30000:30000+(s//10)], training_data_all[35000:35000+(s//10)],\n",
    "                                    training_data_all[40000:40000+(s//10)], training_data_all[45000:45000+(s//10)]), axis=0)\n",
    "    training_label = np.concatenate((training_label_all[0:0+(s//10)], training_label_all[5000:5000+(s//10)],\n",
    "                                     training_label_all[10000:10000+(s//10)], training_label_all[15000:15000+(s//10)],\n",
    "                                     training_label_all[20000:20000+(s//10)], training_label_all[25000:25000+(s//10)],\n",
    "                                     training_label_all[30000:30000+(s//10)], training_label_all[35000:35000+(s//10)],\n",
    "                                     training_label_all[40000:40000+(s//10)], training_label_all[45000:45000+(s//10)]), axis=0)\n",
    "\n",
    "    # training_data = poison_dataset(training_data, poison_rate, trigger_generator)\n",
    "    backdoor_training_dataset = BackdoorDataset(\n",
    "      clean_data=training_data,\n",
    "      clean_labels=tf.one_hot(training_label, depth=10).numpy(),\n",
    "      trigger_obj=trigger_generator,\n",
    "      epsilon=poisoning_rate,\n",
    "      target_label=target_label,\n",
    "      source_label=source_label,\n",
    "      train=True\n",
    "    )\n",
    "    poisoned_training_data, poisoned_training_label = backdoor_training_dataset.get_data()\n",
    "\n",
    "    backdoor_test_dataset = BackdoorDataset(\n",
    "      clean_data=testing_data,\n",
    "      clean_labels=tf.one_hot(testing_label, depth=10).numpy(),\n",
    "      trigger_obj=trigger_generator,  # Adjust this as needed for the trigger type\n",
    "      epsilon=poisoning_rate,  # Apply the same poisoning rate as training\n",
    "      target_label=target_label,\n",
    "      source_label=source_label,\n",
    "      train=False  # Specify that this is for testing\n",
    "    )\n",
    "    poisoned_testing_data, poisoned_testing_label = backdoor_test_dataset.get_data()\n",
    "\n",
    "    # 1-of-K encoding\n",
    "    training_label = tf.reshape(tf.one_hot(training_label, axis=1, depth=10, dtype=tf.float64), (s, 10)).numpy()\n",
    "    testing_label = tf.reshape(tf.one_hot(testing_label, axis=1, depth=10, dtype=tf.float64), (10000, 10)).numpy()\n",
    "\n",
    "    # Shuffling the training set\n",
    "    indices = tf.range(start=0, limit=tf.shape(training_data)[0], dtype=tf.int32)\n",
    "    shuffled_indices = tf.random.shuffle(indices)\n",
    "    training_data = tf.gather(training_data, shuffled_indices, axis=0)\n",
    "    training_label = tf.gather(training_label, shuffled_indices, axis=0)\n",
    "    poisoned_training_data = tf.gather(poisoned_training_data, shuffled_indices, axis=0)\n",
    "    poisoned_training_label = tf.gather(poisoned_training_label, shuffled_indices, axis=0)\n",
    "\n",
    "    # Normalizing and reshaping data\n",
    "    if isinstance(backdoor_training_dataset.trigger_obj, GenerateSQRTrigger): # or isinstance(backdoor_training_dataset.trigger_obj, GenerateWarpedTrigger):  # Check if the trigger is the square trigger\n",
    "      poisoned_training_data = poisoned_training_data / 255\n",
    "      poisoned_testing_data = poisoned_testing_data / 255\n",
    "\n",
    "    training_data=training_data/255\n",
    "    training_data=tf.cast(training_data,dtype=tf.dtypes.float32)\n",
    "    poisoned_training_data = tf.cast(poisoned_training_data, dtype=tf.dtypes.float32)\n",
    "    poisoned_testing_data = tf.cast(poisoned_testing_data, dtype=tf.dtypes.float32)\n",
    "\n",
    "    testing_data = testing_data / 255\n",
    "    testing_data = tf.cast(testing_data, dtype=tf.dtypes.float32)\n",
    "\n",
    "  if dataset == 'GTSRB':\n",
    "    backdoor_training_dataset = BackdoorDataset(\n",
    "      clean_data=training_data,\n",
    "      clean_labels=tf.one_hot(training_label, depth=43).numpy(),\n",
    "      trigger_obj=trigger_generator,\n",
    "      epsilon=poisoning_rate,\n",
    "      target_label=target_label,\n",
    "      source_label=source_label,\n",
    "      train=True,\n",
    "      cifar=False\n",
    "    )\n",
    "    poisoned_training_data, poisoned_training_label = backdoor_training_dataset.get_data()\n",
    "\n",
    "    backdoor_test_dataset = BackdoorDataset(\n",
    "      clean_data=testing_data,\n",
    "      clean_labels=tf.one_hot(testing_label, depth=43).numpy(),\n",
    "      trigger_obj=trigger_generator,  # Adjust this as needed for the trigger type\n",
    "      epsilon=poisoning_rate,  # Apply the same poisoning rate as training\n",
    "      target_label=target_label,\n",
    "      source_label=source_label,\n",
    "      train=False,  # Specify that this is for testing\n",
    "      cifar=False\n",
    "    )\n",
    "    poisoned_testing_data, poisoned_testing_label = backdoor_test_dataset.get_data()\n",
    "\n",
    "    training_label = tf.reshape(tf.one_hot(training_label, depth=43, axis=1, dtype=tf.float64), (len(training_label), 43)).numpy()\n",
    "    testing_label = tf.reshape(tf.one_hot(testing_label, depth=43, axis=1, dtype=tf.float64), (len(testing_label), 43)).numpy()\n",
    "\n",
    "    indices = tf.range(start=0, limit=tf.shape(training_data)[0], dtype=tf.int32)\n",
    "    shuffled_indices = tf.random.shuffle(indices)\n",
    "    training_data = tf.gather(training_data, shuffled_indices, axis=0)\n",
    "    training_label = tf.gather(training_label, shuffled_indices, axis=0)\n",
    "    poisoned_training_data = tf.gather(poisoned_training_data, shuffled_indices, axis=0)\n",
    "    poisoned_training_label = tf.gather(poisoned_training_label, shuffled_indices, axis=0)\n",
    "\n",
    "    if isinstance(backdoor_training_dataset.trigger_obj, GenerateSQRTrigger): # or isinstance(backdoor_training_dataset.trigger_obj, GenerateWarpedTrigger):  # Check if the trigger is the square trigger\n",
    "      poisoned_training_data = poisoned_training_data / 255\n",
    "      poisoned_testing_data = poisoned_testing_data / 255\n",
    "\n",
    "    training_data=training_data/255\n",
    "    training_data=tf.cast(training_data,dtype=tf.dtypes.float32)\n",
    "    poisoned_training_data = tf.cast(poisoned_training_data, dtype=tf.dtypes.float32)\n",
    "    poisoned_testing_data = tf.cast(poisoned_testing_data, dtype=tf.dtypes.float32)\n",
    "\n",
    "    testing_data = testing_data / 255\n",
    "    testing_data = tf.cast(testing_data, dtype=tf.dtypes.float32)\n",
    "\n",
    "  image_patch = poisoned_testing_data[4536:4537]\n",
    "  plt.figure(figsize=(3, 3))\n",
    "  plt.imshow((image_patch[0]), cmap='gray')\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Blend\")\n",
    "  plt.show()\n",
    "  plt.savefig(f'/home/jtelintelo/pmoe_backdoor/result_images/{trigger}_patchlevel-{patch_level}.pdf')\n",
    "\n",
    "  # Creating the model\n",
    "  model_input = tf.keras.Input(shape=(poisoned_training_data.shape[1], poisoned_training_data.shape[2], poisoned_training_data.shape[3]))\n",
    "  if dataset == 'CIFAR-10':\n",
    "    model_output = WideResnet(model_input, num_blocks=1, k=10, num_classes=10)\n",
    "  if dataset == 'GTSRB':\n",
    "    model_output = WideResnet(model_input, num_blocks=1, k=10, num_classes=43)\n",
    "\n",
    "  # Model Aggregation\n",
    "  model = tf.keras.Model(model_input, model_output)\n",
    "  # Model Compilation\n",
    "  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['categorical_accuracy'])\n",
    "\n",
    "  # Callbacks\n",
    "  z = []\n",
    "  weights_dict = {}\n",
    "  patch_assignments = []\n",
    "  def capture_patch_assignments(epoch, logs):\n",
    "    try:\n",
    "      intermediate_model = tf.keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[layer.output[1] for layer in model.layers if isinstance(layer, gate)]\n",
    "      )\n",
    "      # print(\"Intermediate model outputs:\", intermediate_model.outputs)\n",
    "\n",
    "      patch_indices = intermediate_model.predict(image_patch, batch_size=128)\n",
    "      patch_indices = np.array(patch_indices)\n",
    "      epoch_assignments = []  # To store assignments for this epoch\n",
    "      for expert_idx, indices in enumerate(patch_indices):\n",
    "        # Map indices to experts\n",
    "        flattened_indices = indices.flatten()\n",
    "        grid_coordinates = [(i // 8, i % 8) for i in flattened_indices]  # Convert to (row, col)\n",
    "        epoch_assignments.append({\n",
    "          \"expert\": expert_idx + 1,\n",
    "          \"flat_indices\": flattened_indices,\n",
    "          \"grid_coordinates\": grid_coordinates\n",
    "        })\n",
    "\n",
    "      patch_assignments.append(epoch_assignments)\n",
    "      print(f\"Epoch {epoch+1}: Captured patch assignments.\")\n",
    "\n",
    "    except Exception as e:\n",
    "      import traceback\n",
    "      print(f\"Error capturing patch assignments at epoch {epoch+1}: {e}\")\n",
    "      traceback.print_exc()\n",
    "\n",
    "  assignment_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=capture_patch_assignments)\n",
    "  weight_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: weights_dict.update({epoch: model.get_weights()}))\n",
    "\n",
    "  testing_after_epoch = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: z.append(model.evaluate(testing_data, testing_label, batch_size=1000, verbose=1)))\n",
    "\n",
    "\n",
    "  if load_model:\n",
    "    model.load_weights(f'/home/jtelintelo/pmoe_backdoor/model_files/{dataset}_{trigger}_{poisoning_rate}-poisonrate_{n_experts}-experts_patchlevel-{patch_level}.weights.h5')\n",
    "  # Train the Model\n",
    "  if train:  \n",
    "    x = model.fit(poisoned_training_data, poisoned_training_label, batch_size=128, epochs=25,\n",
    "                callbacks=[testing_after_epoch, weight_callback, assignment_callback])\n",
    "    f = f'/home/jtelintelo/pmoe_backdoor/results/test_acc_loss_{dataset}_{trigger}_{poisoning_rate}-poisonrate_{n_experts}-experts_patchlevel-{patch_level}' + str(s // 1000)\n",
    "    np.save(f, z)\n",
    "\n",
    "  asr = calculate_ASR(\n",
    "      model=model,\n",
    "      test_data=poisoned_testing_data,\n",
    "      test_labels=poisoned_testing_label,\n",
    "      target_label=target_label,\n",
    "      source_label=source_label,  # None if source-agnostic\n",
    "      verbose=True\n",
    "  )\n",
    "  print(f\"Attack Success Rate (ASR) for s={s}: {asr}%\")\n",
    "\n",
    "  if save_model:\n",
    "    model.save_weights(f'/home/jtelintelo/pmoe_backdoor/model_files/{dataset}_{trigger}_{poisoning_rate}-poisonrate_{n_experts}-experts_patchlevel-{patch_level}.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "aborted",
     "timestamp": 1750841617034,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "MR-SzQKVEMbR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample point 50000: /home/jtelintelo/pmoe_backdoor/results/test_acc_loss_CIFAR-10_square_0.0005-poisonrate_4-experts_patchlevel-True50\n",
      "Looking for file: /home/jtelintelo/pmoe_backdoor/results/test_acc_loss_CIFAR-10_square_0.0005-poisonrate_4-experts_patchlevel-True50.npy\n",
      "Loaded file: /home/jtelintelo/pmoe_backdoor/results/test_acc_loss_CIFAR-10_square_0.0005-poisonrate_4-experts_patchlevel-True50.npy\n",
      "Average Accuracy and Loss (last epoch):\n",
      "[[5.65334439e-01 8.43400002e-01 5.00000000e+04]]\n",
      "Standard Deviation (last epoch):\n",
      "[[    0.     0. 50000.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Attack accuracy: 18.36%\n",
      "Attack Success Rate (ASR) for s=50000: 18.355555555555554%\n"
     ]
    }
   ],
   "source": [
    "def avg_stddev_calc(f, no_v):\n",
    "  t_1 = None\n",
    "  for i in range(no_v):\n",
    "    # f_t = f + '_v' + str(i + 1) + '.npy'  # Construct the file name\n",
    "    f_t = f + '.npy'  # Construct the file name\n",
    "    print(f\"Looking for file: {f_t}\")  # Debugging: Print the file path\n",
    "\n",
    "    try:\n",
    "      t = np.load(f_t)  # Attempt to load the file\n",
    "      print(f\"Loaded file: {f_t}\")  # Confirm the file was loaded successfully\n",
    "      t = tf.reshape(t, (1, tf.shape(t)[0], tf.shape(t)[1])).numpy()\n",
    "\n",
    "      if t_1 is None:\n",
    "        t_1 = t\n",
    "      else:\n",
    "        t_1 = tf.concat((t_1, t), axis=0).numpy()\n",
    "    except FileNotFoundError:\n",
    "      print(f\"File {f_t} not found. Skipping.\")\n",
    "\n",
    "  if t_1 is None:\n",
    "    raise ValueError(\"No valid files found for computation.\")\n",
    "\n",
    "  t_av = tf.math.reduce_mean(t_1, axis=0).numpy()\n",
    "  t_std = tf.math.reduce_std(t_1, axis=0).numpy()\n",
    "  return t_av, t_std\n",
    "\n",
    "\n",
    "def last_epoch_result_collection(f, no_sample_points, points, no_v=5, last_epoch=50):\n",
    "  t_av_s = np.zeros((no_sample_points, 3), dtype=np.float64)\n",
    "  t_std_s = np.zeros((no_sample_points, 3), dtype=np.float64)\n",
    "\n",
    "  for i in range(no_sample_points):\n",
    "    f_1 = f'/home/jtelintelo/pmoe_backdoor/results/test_acc_loss_{dataset}_{trigger}_{poisoning_rate}-poisonrate_{n_experts}-experts_patchlevel-{patch_level}' + str(s // 1000)  # Construct base filename for each sample point\n",
    "    print(f\"Processing sample point {points[i]}: {f_1}\")  # Debugging: Print base file name\n",
    "\n",
    "    t_av, t_std = avg_stddev_calc(f_1, no_v)  # Get average and stddev\n",
    "\n",
    "    t_av_s[i, 0] = t_av[last_epoch - 1, 0]  # Accuracy at the last epoch\n",
    "    t_av_s[i, 1] = t_av[last_epoch - 1, 1]  # Loss at the last epoch\n",
    "    t_av_s[i, 2] = points[i]  # Sample size\n",
    "\n",
    "    t_std_s[i, 0] = t_std[last_epoch - 1, 0]  # Stddev of accuracy\n",
    "    t_std_s[i, 1] = t_std[last_epoch - 1, 1]  # Stddev of loss\n",
    "    t_std_s[i, 2] = points[i]  # Sample size\n",
    "\n",
    "  return t_av_s, t_std_s\n",
    "\n",
    "# Set file and sample information\n",
    "f_moe = 'test_acc_loss_cifar_10_no_noise_wideresnet_moe'\n",
    "no_sample_points = 1\n",
    "points = [50000]\n",
    "no_v = 1\n",
    "last_epoch = 25\n",
    "\n",
    "# Perform analysis\n",
    "try:\n",
    "  wideresnet_moe_av_s, wideresnet_moe_std_s = last_epoch_result_collection(f_moe, no_sample_points, points, no_v, last_epoch)\n",
    "\n",
    "  # Print results\n",
    "  print(\"Average Accuracy and Loss (last epoch):\")\n",
    "  print(wideresnet_moe_av_s)\n",
    "  print(\"Standard Deviation (last epoch):\")\n",
    "  print(wideresnet_moe_std_s)\n",
    "\n",
    "  # Plot results\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  plt.errorbar(wideresnet_moe_av_s[:, 2], wideresnet_moe_av_s[:, 1], wideresnet_moe_std_s[:, 1],\n",
    "                marker='^', label='Wideresnet-MoE')\n",
    "  plt.legend()\n",
    "  plt.xlabel('No. of training samples')\n",
    "  plt.ylabel('Test accuracy')\n",
    "  plt.title('CIFAR-10: Wideresnet vs. Wideresnet-MoE')\n",
    "  plt.show()\n",
    "\n",
    "except ValueError as e:\n",
    "  print(f\"Error during analysis: {e}\")\n",
    "\n",
    "asr = calculate_ASR(\n",
    "    model=model,\n",
    "    test_data=poisoned_testing_data,\n",
    "    test_labels=poisoned_testing_label,\n",
    "    target_label=target_label,\n",
    "    source_label=source_label,  # None if source-agnostic\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"Attack Success Rate (ASR) for s={s}: {asr}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1750841617038,
     "user": {
      "displayName": "Jona te Lintelo",
      "userId": "10992960807295070461"
     },
     "user_tz": -120
    },
    "id": "bUJ8rR3kFxUI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
